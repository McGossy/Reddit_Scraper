{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import datetime\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('reddit_info.json')\n",
    "info = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basically logs into the bot? I think\n",
    "def create_reddit_object():\n",
    "    reddit = praw.Reddit(client_id = info['client_id'],\n",
    "                        client_secret = info['client_secret'],\n",
    "                        user_agent = info['user_agent'],\n",
    "                        username = info['username'],\n",
    "                        password = info['password'])\n",
    "    return reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_string(s):\n",
    "    no_digits = []\n",
    "\n",
    "    # Convert string to lowercase, remove punctuation.\n",
    "    raw_string = s.lower()\n",
    "    clean_string = raw_string.translate(str.maketrans('','', string.punctuation))\n",
    "\n",
    "    # Remove all digits from string.\n",
    "    for letter in clean_string:\n",
    "        if not letter.isdigit():\n",
    "            no_digits.append(letter)\n",
    "\n",
    "    # Create the final string.\n",
    "    result = ''.join(no_digits)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i’ve\nfound\na\nfew\nfunny\nmemories\nduring\nlockdown\nthis\nis\nfrom\nmy\nst\ntour\nin\nbackstage\nin\nvegas\njoe\nbiden\nelected\npresident\nof\nthe\nunited\nstates\na\nshort\nstory\nplease\nmake\nthis\ngo\nviral\ni\nam\nbegging\nyou\npolice\nand\nnational\nguard\npatrolling\nneighborhood\nand\nshooting\ncivilians\non\ntheir\nown\nproperty\nmake\namerica\nsee\nthis\ni\nbeg\nyou\nminneapolis\nif\nthis\nis\nyou\nfuck\nyou\nleaked\ndrone\nfootage\nof\nshackled\nand\nblindfolded\nuighur\nmuslims\nled\nfrom\ntrains\nas\na\ngerman\nthis\nis\nespecially\nchilling\neverybodys\ntrying\nto\nshame\nus\nshe\ndid\nher\nbest\nok\nat\na\nprotest\nin\narizona\nmeet\nthe\nnewest\nmember\nof\nthe\nfamily\ndutch\nthis\nhouse\nain’t\nbig\nenough\nfor\nthe\nsix\nof\nus\nthey\nwhat\nmile\nflight\nhour\ndrive\nhour\nhike\nand\nmy\nwife\nis\nat\nrest\nthis\nman\njogged\nmiles\nthrough\nhis\nneighborhood\ncarrying\na\ntv\nin\nhis\nhands\nto\nprove\nthat\n“looking\nlike\na\nsuspect”\nwho\ncommitted\na\nrobbery\nisn’t\na\ngood\nenough\nexcuse\nfor\nthe\nmurder\nof\nahmaud\narbery\nneighbors\nwaived\nhello\nto\nhim\nas\nhe\njogged\nevery\nday\ngeneral\ngrievous\nadds\na\nunique\nlightsaber\nto\nhis\ncollection\nday\nfinale\nevery\nuraymesiris\nsuggestion\npresident\ndonald\ntrump\nsays\nhe\nhas\ntested\npositive\nfor\ncoronavirus\noregon\nwildfires\nmaking\nit\nlook\nstraight\napocalyptic\nfirst\nday\nof\nschool\nin\na\ngeorgia\ntown\none\nof\nthe\nbiggest\nvirus\nhot\nzones\nin\nthe\nworld\nin\nengland\nyou\nsometimes\nsee\nthese\nwavy\nbrick\nfences\nand\ncurious\nas\nit\nmay\nseem\nthis\nshape\nuses\nfewer\nbricks\nthan\na\nstraight\nwall\na\nstraight\nwall\nneeds\nat\nleast\ntwo\nlayers\nof\nbricks\nto\nmake\nis\nsturdy\nbut\nthe\nwavy\nwall\nis\nfine\nthanks\nto\nthe\narch\nsupport\nprovided\nby\nthe\nwaves\nthis\nis\nthe\nworst\npicture\never\ntaken\nof\nme\nafter\nhospital\ndays\nand\nlosing\nkg\nmy\nyr\nold\ndad\nis\nhome\nand\nrecovered\nfrom\ncovid\nin\nmadrid\nwe\nare\ndoomed\nthe\ndenver\nbroncos\nhave\nthe\nentire\ntown\nof\n‘south\npark’\nin\nthe\nstands\nfor\ntoday’s\nnfl\ngame\nhmmmmmmmmmm\nnickelodeon\nwent\noff\nthe\nair\nfor\na\nfull\nminutes\nand\nseconds\nto\nprotest\npolice\nbrutality\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_common_words():\n",
    "\n",
    "    reddit = create_reddit_object()\n",
    "\n",
    "\n",
    "    #chooses subreddit\n",
    "    subreddit = reddit.subreddit(\"popular\")\n",
    "    hot = subreddit.top(\"year\", limit = 25)\n",
    "\n",
    "    wordcounts = {}\n",
    "\n",
    "    for submission in hot:\n",
    "        for word in _process_string(submission.title).split():\n",
    "            if word not in stopwords:\n",
    "                if word not in wordcounts:\n",
    "                    wordcounts[word] = 1\n",
    "                else:\n",
    "                    wordcounts[word] += 1\n",
    "    return wordcounts\n",
    "        # raw_string = submission.title.lower()\n",
    "        # clean_string = raw_string.translate(str.maketrans('', '', string.punctuation))\n",
    "        # print(clean_string)\n",
    "        # for word in submission.title.lower().split():\n",
    "        #     word = word.replace(\".\",\"\")\n",
    "        #     word = word.replace(\",\",\"\")\n",
    "        #     word = word.replace(\":\",\"\")\n",
    "        #     word = word.replace(\"\\\"\",\"\")\n",
    "        #     word = word.replace(\"!\",\"\")\n",
    "        #     word = word.replace(\"*\",\"\")\n",
    "\n",
    "        #     print(word)\n",
    "find_common_words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "time_filter must be one of: year, hour, all, month, week, day",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-cf2429681334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#chooses the 'hot' category and sets it to search through the first 25 posts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# unique_words = dict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/praw/models/listing/mixins/base.py\u001b[0m in \u001b[0;36mtop\u001b[0;34m(self, time_filter, **generator_kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_time_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safely_add_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"params\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"top\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/praw/models/listing/mixins/base.py\u001b[0m in \u001b[0;36m_validate_time_filter\u001b[0;34m(time_filter)\u001b[0m\n\u001b[1;32m     26\u001b[0m             raise ValueError(\n\u001b[1;32m     27\u001b[0m                 \"time_filter must be one of: {}\".format(\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseListingMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALID_TIME_FILTERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 )\n\u001b[1;32m     30\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: time_filter must be one of: year, hour, all, month, week, day"
     ]
    }
   ],
   "source": [
    "#chooses the 'hot' category and sets it to search through the first 25 posts\n",
    "hot = subreddit.top(\"hot\", limit = 10)\n",
    "\n",
    "    \n",
    "# unique_words = dict()\n",
    "# for submission in popular:\n",
    "#     title = submission.title\n",
    "#     for word in title.split():\n",
    "#         if word not in unique_words:\n",
    "#             unique_words[word] = 1\n",
    "#         else:\n",
    "#             unique_words[word] += 1\n",
    "\n",
    "# print(\"\\n\\nPrinting Words\")\n",
    "# for word in unique_words:\n",
    "#     print(word, ':', unique_words[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}