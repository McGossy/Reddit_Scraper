{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import datetime\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('reddit_info.json')\n",
    "info = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basically logs into the bot? I think\n",
    "def create_reddit_object():\n",
    "    reddit = praw.Reddit(client_id = info['client_id'],\n",
    "                        client_secret = info['client_secret'],\n",
    "                        user_agent = info['user_agent'],\n",
    "                        username = info['username'],\n",
    "                        password = info['password'])\n",
    "    return reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_string(s):\n",
    "    no_digits = []\n",
    "\n",
    "    # Convert string to lowercase, remove punctuation.\n",
    "    raw_string = s.lower()\n",
    "    clean_string = raw_string.translate(str.maketrans('','', string.punctuation))\n",
    "\n",
    "    # Remove all digits from string.\n",
    "    for letter in clean_string:\n",
    "        if not letter.isdigit():\n",
    "            no_digits.append(letter)\n",
    "\n",
    "    # Create the final string.\n",
    "    result = ''.join(no_digits)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'i’ve': 1, 'found': 1, 'funny': 1, 'memories': 1, 'lockdown': 1, 'tour': 1, 'backstage': 1, 'vegas': 1, 'joe': 1, 'biden': 1, 'elected': 1, 'president': 2, 'united': 1, 'states': 1, 'short': 1, 'story': 1, 'please': 1, 'make': 3, 'viral': 1, 'begging': 1, 'police': 2, 'national': 1, 'guard': 1, 'patrolling': 1, 'neighborhood': 2, 'shooting': 1, 'civilians': 1, 'property': 1, 'america': 1, 'see': 2, 'beg': 1, 'minneapolis': 1, 'fuck': 1, 'leaked': 1, 'drone': 1, 'footage': 1, 'shackled': 1, 'blindfolded': 1, 'uighur': 1, 'muslims': 1, 'led': 1, 'trains': 1, 'german': 1, 'especially': 1, 'chilling': 1, 'everybodys': 1, 'trying': 1, 'shame': 1, 'best': 1, 'protest': 2, 'arizona': 1, 'meet': 1, 'newest': 1, 'member': 1, 'family': 1, 'dutch': 1, 'house': 1, 'ain’t': 1, 'big': 1, 'enough': 2, 'six': 1, 'mile': 1, 'flight': 1, 'hour': 2, 'drive': 1, 'hike': 1, 'wife': 1, 'rest': 1, 'man': 1, 'jogged': 2, 'miles': 1, 'carrying': 1, 'hands': 1, 'prove': 1, '“looking': 1, 'like': 1, 'suspect”': 1, 'committed': 1, 'robbery': 1, 'isn’t': 1, 'good': 1, 'excuse': 1, 'murder': 1, 'ahmaud': 1, 'arbery': 1, 'neighbors': 1, 'waived': 1, 'hello': 1, 'every': 2, 'day': 3, 'general': 1, 'grievous': 1, 'adds': 1, 'unique': 1, 'lightsaber': 1, 'collection': 1, 'finale': 1, 'uraymesiris': 1, 'suggestion': 1, 'donald': 1, 'trump': 1, 'says': 1, 'tested': 1, 'positive': 1, 'coronavirus': 1, 'oregon': 1, 'wildfires': 1, 'making': 1, 'look': 1, 'straight': 3, 'apocalyptic': 1, 'first': 1, 'school': 1, 'georgia': 1, 'town': 2, 'one': 1, 'biggest': 1, 'virus': 1, 'hot': 1, 'zones': 1, 'world': 1, 'england': 1, 'sometimes': 1, 'wavy': 2, 'brick': 1, 'fences': 1, 'curious': 1, 'may': 1, 'seem': 1, 'shape': 1, 'uses': 1, 'fewer': 1, 'bricks': 2, 'wall': 3, 'needs': 1, 'least': 1, 'two': 1, 'layers': 1, 'sturdy': 1, 'fine': 1, 'thanks': 1, 'arch': 1, 'support': 1, 'provided': 1, 'waves': 1, 'worst': 1, 'picture': 1, 'ever': 1, 'taken': 1, 'hospital': 1, 'days': 1, 'losing': 1, 'old': 1, 'dad': 1, 'home': 1, 'recovered': 1, 'covid': 1, 'madrid': 1, 'doomed': 1, 'denver': 1, 'broncos': 1, 'entire': 1, '‘south': 1, 'park’': 1, 'stands': 1, 'today’s': 1, 'nfl': 1, 'game': 1, 'hmmmmmmmmmm': 1, 'nickelodeon': 1, 'went': 1, 'air': 1, 'full': 1, 'minutes': 1, 'seconds': 1, 'brutality': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_common_words():\n",
    "\n",
    "    reddit = create_reddit_object()\n",
    "\n",
    "\n",
    "    #chooses subreddit\n",
    "    subreddit = reddit.subreddit(\"popular\")\n",
    "    hot = subreddit.top(\"year\", limit = 25)\n",
    "\n",
    "    wordcounts = {}\n",
    "\n",
    "    for submission in hot:\n",
    "        for word in _process_string(submission.title).split():\n",
    "            if word not in stopwords.words('english') and len(word) > 2:\n",
    "                if word not in wordcounts:\n",
    "                    wordcounts[word] = 1\n",
    "                else:\n",
    "                    wordcounts[word] += 1\n",
    "    return wordcounts\n",
    "\n",
    "print(find_common_words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}