{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/bruce/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import datetime\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "nltk.download('vader_lexicon')\n",
    "import string\n",
    "import pandas as pd\n",
    "import collections\n",
    "from pprint import pprint\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('reddit_info.json')\n",
    "info = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basically logs into the bot? I think\n",
    "def create_reddit_object():\n",
    "    reddit = praw.Reddit(client_id = info['client_id'],\n",
    "                        client_secret = info['client_secret'],\n",
    "                        user_agent = info['user_agent'],\n",
    "                        username = info['username'],\n",
    "                        password = info['password'])\n",
    "    return reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_popular():\n",
    "    headlines = set()\n",
    "\n",
    "    reddit = create_reddit_object()\n",
    "\n",
    "    popular = reddit.subreddit(\"popular\")\n",
    "    popular_year = popular.top(\"year\", limit=10)\n",
    "\n",
    "    for submission in popular_year:\n",
    "        headlines.add(submission.title)\n",
    "\n",
    "    return headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_news():\n",
    "    headlines = set()\n",
    "\n",
    "    # reddit = create_reddit_object()\n",
    "\n",
    "    news = reddit.subreddit(\"science\")\n",
    "    news_year = news.top(\"year\", limit=10)\n",
    "\n",
    "    for submission in news_year:\n",
    "        headlines.add(submission.title)\n",
    "\n",
    "    return headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Please make this go viral. I am begging you. Police and National Guard patrolling neighborhood and shooting civilians on their own property. Make America see this, I beg you. [Minneapolis]', 'I’ve found a few funny memories during lockdown. This is from my 1st tour in 89, backstage in Vegas.', 'If this is you: Fuck you', 'Leaked Drone footage of shackled and blindfolded Uighur Muslims led from trains. As a German this is especially chilling.', 'Meet the newest member of the family, Dutch!', 'At a protest in Arizona', 'She did her best ok?', 'A short story', 'Joe Biden elected president of the United States', '\"Everybody\\'s trying to shame us\"'}\n",
      "\n",
      "{'LED lights found to kill coronavirus efficiently, quickly, and cheaply, a global first in fight against COVID-19. The finding suggests the UV-LEDs can be installed in air conditioning and water systems. It requires less than half a minute to destroy more than 99.9% of coronaviruses.', 'The first severe COVID-19 patient successfully treated with human recombinant soluble ACE2 (hrsACE2), with disappearance of coronavirus swiftly from the serum, nasal cavity and lungs, and a reduction of inflammatory cytokine levels, leading to a significant clinical improvement.', 'Bird deaths down 70 percent after painting wind turbine blades', 'Research finds that crows know what they know and can ponder the content of their own minds, a manifestation of higher intelligence and analytical thought long believed the sole province of humans and a few other higher mammals.', 'Marijuana use among college students has been trending upward for years, but in states that have legalized recreational marijuana, use has jumped even higher. After legalization, however, students showed a greater drop in binge drinking than their peers in states where marijuana is not legal.', 'The first human trial of a COVID-19 vaccine finds that it is safe, well-tolerated, and induces a rapid immune response: “These results represent an important milestone.”', 'Testing half the population weekly with inexpensive, rapid COVID-19 tests would drive the virus toward elimination within weeks, even if the tests are less sensitive than gold-standard. This could lead to “personalized stay-at-home orders” without shutting down restaurants, bars, retail and schools.', 'A new study in The Lancet by a team of Yale epidemiologists finds that Medicare for All would save more than 68,000 lives annually as well as $450 billion in cost', 'In the US, states typically pay for prison while counties determine sentencing. A natural experiment whereby the cost burden of juvenile incarceration was placed on counties led to a stark drop in incarceration. This suggests that mass incarceration in the US is in part due to misaligned incentives.', \"Venom from honeybees has been found to rapidly kill aggressive and hard-to-treat breast cancer cells, finds new Australian research. The study also found when the venom's main component was combined with existing chemotherapy drugs, it was extremely efficient at reducing tumour growth in mice.\"}\n"
     ]
    }
   ],
   "source": [
    "print(compile_popular())\n",
    "print()\n",
    "print(compile_news())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compile_subreddits(subreddits):\n",
    "    headlines = set()\n",
    "\n",
    "    reddit = create_reddit_object()\n",
    "\n",
    "    for i in range(len(subreddits)):\n",
    "        subreddit = reddit.subreddit(subreddits[i])\n",
    "        top_headlines_in_year = subreddit.top(\"year\", limit=None)\n",
    "\n",
    "        for submission in top_headlines_in_year:\n",
    "            headlines.add(submission.title)\n",
    "    \n",
    "    return headlines\n",
    "\n",
    "\n",
    "# print(compile_subreddits([\"popular\", \"news\", \"all\", \"politics\", \"worldnews\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer(headlines):\n",
    "    sia = SIA()\n",
    "    results = []\n",
    "\n",
    "    for line in headlines:\n",
    "        pol_score = sia.polarity_scores(line)\n",
    "        pol_score['headline'] = line\n",
    "        results.append(pol_score)\n",
    "\n",
    "    df = pd.DataFrame.from_records(results)\n",
    "\n",
    "    return df\n",
    "    # pprint(results[:3], width=100)"
   ]
  },
  {
   "source": [
    "# all_headlines = compile_subreddits([\"popular\", \"news\", \"all\", \"politics\", \"worldnews\"])\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Positive headlines:\n\n['It was fun doe',\n 'LAPD shoots “less than lethal” rounds directly at an unarmed homeless man who was not protesting.',\n 'The sun shining through my fish tank aligned perfectly on each knob',\n 'Decorated Afghan pilot who protected US airmen in hiding after Pentagon reverses approval to come to US.',\n 'Bollywood Actors Called Out For Supporting Black Lives Matter Movement While Promoting Skin Lightening Products']\n\nNegative headlines:\n\n['Prince Andrew has given ‘zero cooperation’ in Jeffrey Epstein sex crime investigation, federal prosecutors say',\n 'Cincinnati church wipes out $46.5 million in medical debt for 45,000 families',\n 'WHO sounds alarm as coronavirus cases rise by one million in five days',\n 'Alabama blocked a man from voting because he owed $4',\n \"Australia to pass surveillance bill that'll allow children as young as 14 to be interrogated by government agents and could see journalists jailed for 5 years for refusing to reveal sources. \"\n 'Authorities could hack, secretly takeover, and add, copy, and delete material on computers.']\n-1    1557\n 0    1509\n 1     870\nName: label, dtype: int64\n-1    39.557927\n 0    38.338415\n 1    22.103659\nName: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = sentiment_analyzer(all_headlines)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "df['label'] = 0\n",
    "df.loc[df['compound'] > 0.2, 'label'] = 1\n",
    "df.loc[df['compound'] < -0.2, 'label'] = -1\n",
    "df.head()\n",
    "\n",
    "df2 = df[['headline', 'label']]\n",
    "\n",
    "print(\"Positive headlines:\\n\")\n",
    "pprint(list(df[df['label'] == 1].headline)[:5], width=200)\n",
    "\n",
    "print(\"\\nNegative headlines:\\n\")\n",
    "pprint(list(df[df['label'] == -1].headline)[:5], width=200)\n",
    "\n",
    "print(df.label.value_counts())\n",
    "\n",
    "print(df.label.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(headlines):\n",
    "    tokens = []\n",
    "    for line in headlines:\n",
    "        toks = tokenizer.tokenize(line)\n",
    "        toks = [t.lower() for t in toks if t.lower() not in stopwords.words('english')]\n",
    "        tokens.extend(toks)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      neg    neu    pos  compound  \\\n",
       "2   0.000  0.476  0.524    0.5106   \n",
       "13  0.000  0.865  0.135    0.3252   \n",
       "20  0.000  0.724  0.276    0.6369   \n",
       "32  0.099  0.631  0.270    0.5859   \n",
       "41  0.000  0.649  0.351    0.6705   \n",
       "\n",
       "                                             headline  label  \n",
       "2                                      It was fun doe      1  \n",
       "13  LAPD shoots “less than lethal” rounds directly...      1  \n",
       "20  The sun shining through my fish tank aligned p...      1  \n",
       "32  Decorated Afghan pilot who protected US airmen...      1  \n",
       "41  Bollywood Actors Called Out For Supporting Bla...      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>neg</th>\n      <th>neu</th>\n      <th>pos</th>\n      <th>compound</th>\n      <th>headline</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.000</td>\n      <td>0.476</td>\n      <td>0.524</td>\n      <td>0.5106</td>\n      <td>It was fun doe</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.000</td>\n      <td>0.865</td>\n      <td>0.135</td>\n      <td>0.3252</td>\n      <td>LAPD shoots “less than lethal” rounds directly...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.000</td>\n      <td>0.724</td>\n      <td>0.276</td>\n      <td>0.6369</td>\n      <td>The sun shining through my fish tank aligned p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.099</td>\n      <td>0.631</td>\n      <td>0.270</td>\n      <td>0.5859</td>\n      <td>Decorated Afghan pilot who protected US airmen...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.000</td>\n      <td>0.649</td>\n      <td>0.351</td>\n      <td>0.6705</td>\n      <td>Bollywood Actors Called Out For Supporting Bla...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "df[df.label==1].head()\n",
    "\n",
    "# pos_lines = list(df[df.label == 1].headline)\n",
    "\n",
    "# pos_tokens = process_text(pos_lines)\n",
    "# pos_freq = nltk.FreqDist(pos_tokens)\n",
    "\n",
    "# pos_freq.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('trump', 333),\n",
       " ('police', 153),\n",
       " ('says', 147),\n",
       " ('coronavirus', 134),\n",
       " ('covid', 113),\n",
       " ('us', 92),\n",
       " ('19', 88),\n",
       " ('people', 75),\n",
       " ('man', 66),\n",
       " ('protesters', 63),\n",
       " ('president', 59),\n",
       " ('death', 59),\n",
       " ('u', 58),\n",
       " ('black', 56),\n",
       " ('white', 53),\n",
       " ('arrested', 49),\n",
       " ('charged', 49),\n",
       " ('new', 49),\n",
       " ('one', 47),\n",
       " ('world', 45),\n",
       " ('election', 43),\n",
       " ('china', 43),\n",
       " ('say', 41),\n",
       " ('house', 41),\n",
       " ('years', 40),\n",
       " ('officer', 38),\n",
       " ('biden', 38),\n",
       " ('000', 37),\n",
       " ('killed', 37),\n",
       " ('year', 37),\n",
       " ('protests', 37),\n",
       " ('officers', 36),\n",
       " ('dead', 35),\n",
       " ('donald', 35),\n",
       " ('woman', 35),\n",
       " ('two', 34),\n",
       " ('fired', 34),\n",
       " ('stop', 34),\n",
       " ('calls', 33),\n",
       " ('said', 33),\n",
       " ('video', 33),\n",
       " ('first', 31),\n",
       " ('protest', 31),\n",
       " ('died', 31),\n",
       " ('floyd', 30),\n",
       " ('state', 29),\n",
       " ('ban', 29),\n",
       " ('pandemic', 29),\n",
       " ('family', 28),\n",
       " ('old', 28),\n",
       " ('anti', 28),\n",
       " ('news', 27),\n",
       " ('war', 27),\n",
       " ('george', 27),\n",
       " ('health', 27),\n",
       " ('could', 26),\n",
       " ('day', 26),\n",
       " ('fraud', 26),\n",
       " ('law', 26),\n",
       " ('would', 26),\n",
       " ('prison', 26),\n",
       " ('government', 25),\n",
       " ('crisis', 25),\n",
       " ('accused', 25),\n",
       " ('court', 25),\n",
       " ('million', 24),\n",
       " ('bill', 24),\n",
       " ('report', 24),\n",
       " ('home', 24),\n",
       " ('call', 23),\n",
       " ('iran', 23),\n",
       " ('campaign', 23),\n",
       " ('2', 23),\n",
       " ('found', 23),\n",
       " ('canada', 23),\n",
       " ('right', 23),\n",
       " ('killing', 22),\n",
       " ('shot', 22),\n",
       " ('american', 22),\n",
       " ('get', 22),\n",
       " ('1', 21),\n",
       " ('shooting', 21),\n",
       " ('general', 21),\n",
       " ('human', 21),\n",
       " ('fire', 20),\n",
       " ('americans', 20),\n",
       " ('attack', 20),\n",
       " ('officials', 20),\n",
       " ('poor', 20),\n",
       " ('michigan', 20),\n",
       " ('arrest', 20),\n",
       " ('child', 20),\n",
       " ('claims', 19),\n",
       " ('thousands', 19),\n",
       " ('women', 19),\n",
       " ('judge', 19),\n",
       " ('hong', 19),\n",
       " ('federal', 18),\n",
       " ('shows', 18),\n",
       " ('response', 18)]"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "neg_lines = list(df2[df2.label == -1].headline)\n",
    "\n",
    "neg_tokens = process_text(neg_lines)\n",
    "neg_freq = nltk.FreqDist(neg_tokens)\n",
    "\n",
    "neg_freq.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' Remove punctuation and digits from a string. '''\n",
    "def _process_string(s):\n",
    "    no_digits = []\n",
    "\n",
    "    # Convert string to lowercase, remove punctuation.\n",
    "    raw_string = s.lower()\n",
    "    clean_string = raw_string.translate(str.maketrans('','', string.punctuation))\n",
    "\n",
    "    # Remove all digits from string.\n",
    "    for letter in clean_string:\n",
    "        if not letter.isdigit():\n",
    "            no_digits.append(letter)\n",
    "\n",
    "    # Create the final string.\n",
    "    result = ''.join(no_digits)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "988\n"
     ]
    }
   ],
   "source": [
    "# /r/popular, /r/news, /r/all, /r/science, /r/politics, /r/worldnews\n",
    "def find_common_words():\n",
    "\n",
    "    reddit = create_reddit_object()\n",
    "\n",
    "\n",
    "    #chooses subreddit\n",
    "    subreddit = reddit.subreddit(\"popular\")\n",
    "    hot = subreddit.top(\"year\", limit = None)\n",
    "\n",
    "    headlines = set()\n",
    "\n",
    "        \n",
    "\n",
    "#     wordcounts = {}\n",
    "\n",
    "#     for submission in hot:\n",
    "#         for word in _process_string(submission.title).split():\n",
    "#             if word not in stopwords.words('english') and len(word) > 2:\n",
    "#                 if word not in wordcounts:\n",
    "#                     wordcounts[word] = 1\n",
    "#                 else:\n",
    "#                     wordcounts[word] += 1\n",
    "#     return wordcounts\n",
    "\n",
    "# word_counter = collections.Counter(find_common_words())\n",
    "# for word, count in word_counter.most_common(500):\n",
    "#     print(word, \":\", count)\n",
    "\n",
    "find_common_words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}